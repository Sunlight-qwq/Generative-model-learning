{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from denoising_diffusion_pytorch import Unet\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = torchvision.datasets.MNIST(root='../dataset', \n",
    "    train=True, transform=torchvision.transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (1, 28, 28)\n",
    "num_steps = 100\n",
    "gpu = torch.device(\"cuda\")\n",
    "\n",
    "betas = torch.linspace(0.0001, 0.02, num_steps).to(gpu)\n",
    "alphas = 1. - betas\n",
    "alphas_bar = torch.cumprod(alphas, dim=0)\n",
    "alphas_bar_sqrt = alphas_bar.sqrt()\n",
    "betas_bar_sqrt = torch.sqrt(1. - alphas_bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_t(x_0: torch.Tensor, t: torch.Tensor, e_t: Optional[torch.Tensor]=None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Get x_t by x_0 and t.\n",
    "    \"\"\"\n",
    "    if e_t is None:\n",
    "        e_t = torch.randn_like(x_0)\n",
    "    \n",
    "    return x_0 * alphas_bar_sqrt[t].reshape(-1, 1, 1, 1)\\\n",
    "         + e_t * betas_bar_sqrt[t].reshape(-1, 1, 1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Unet` 参数：\n",
    "\n",
    "* `dim` 为中间隐含层的通道数\n",
    "* `dim_mults` 为隐含层的压缩倍数\n",
    "* `channels` 为输入的通道数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = Unet(dim=16, dim_mults=(1, 2, 4), channels=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "epochs = 1000\n",
    "lr = 1e-3\n",
    "\n",
    "\n",
    "loader = data.DataLoader(mnist_dataset, batch_size, shuffle=True)\n",
    "mse = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(unet.parameters(), lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.to(gpu)\n",
    "unet.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    sum_loss = 0.\n",
    "    cnt = 0\n",
    "\n",
    "    for x, _ in loader:\n",
    "        x = x.to(gpu)\n",
    "        t = torch.randint(0, num_steps, size=(batch_size,)).long().to(gpu)\n",
    "        e_t = torch.randn_like(x)\n",
    "        x_t = get_x_t(x, t, e_t)\n",
    "        e_hat: torch.Tensor = unet(x_t, t)\n",
    "        loss: torch.Tensor = mse(e_hat, e_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        sum_loss += float(loss)\n",
    "        cnt += 1\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}, loss {sum_loss / cnt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = torch.load(\"./unet.pkl\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(num: int) -> torch.Tensor:\n",
    "    unet.eval()\n",
    "    x_t = torch.randn((num, *shape)).to(gpu)\n",
    "    for t in reversed(range(num_steps)):\n",
    "        z_t = torch.randn_like(x_t) if t > 0 else torch.zeros_like(x_t)\n",
    "        t = t * torch.ones(num).long().to(gpu)\n",
    "        # print(x_t.shape, t.shape)\n",
    "        e_hat = unet(x_t, t)\n",
    "        t = t.reshape(-1, 1, 1, 1)\n",
    "        x_t = 1 / alphas[t].sqrt() * (x_t - betas[t] / betas_bar_sqrt[t] * e_hat) \\\n",
    "            + betas[t] * z_t\n",
    "    return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = generate(100)\n",
    "\n",
    "x.shape\n",
    "\n",
    "for k in range(100):\n",
    "    plt.subplot(10, 10, k + 1)\n",
    "    plt.imshow(x[k].cpu().numpy().squeeze(), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "\n",
    "\n",
    "save_image(x[1], \"1.png\", normalize=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30c009117544208c4bb5d57caa781a071f5348120354d3bb6bf18f9082603c7f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.18 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
